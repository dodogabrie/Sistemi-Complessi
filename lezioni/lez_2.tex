\section{Richiami di Teoria della probabilità}%
\label{sub:Lezione 2}
\mylocaltoc

\subsection{Correlazione e densità spettrale}%
\label{sub:Correlazione e densità spettrale}
\begin{bluebox}{Correlazione}
    \begin{equation}
        G\left(t\right)=\lim_{T \to \infty} \frac{1}{T}\int_{0}^{T} x\left(t+s\right) x\left(s\right)ds
	\label{eq:Gt_init}
    \end{equation}
\end{bluebox}
\noindent
Se il sistema è ergodico questa definizione è equivalente a quella mediata sull'Ensemble:
\begin{equation}
    G( t) = \left<x(t+s) \cdot  x(s)\right>\label{eq:Gt}
\end{equation}
\begin{bluebox}{Densità spettrale}
    Data la trasformata di Fourier di un segnale $x(t)$:
    \[
	y(\omega) = \int_{0}^{T} x\left(t\right)e^{-i\omega t}dt
    \]
    Si definisce la densità spettrale come:
    \[
        S\left(\omega\right) = \lim_{T \to \infty} \frac{1}{2\pi T}\left|y(\omega) \right|^2
    .\] 
\end{bluebox}
\noindent
Le due definizioni sono legate da una trasformata di Fourier: 
\begin{bluebox}{}
    \begin{align}
	&S\left(\omega\right) = \frac{1}{2\pi}\int G\left(\tau\right)e^{-i\omega \tau}d\tau\\
	&G(t) = \int e^{i\omega t)} S(\omega) d\omega \label{eq:G_inv}
    \end{align}
\end{bluebox}
\noindent
L'equazione \ref{eq:G_inv} risulta particolarmente utile per calcolare la correlazione $G(t)$ di un segnale $x(t)$:
\begin{itemize}
    \item Si calcola la trasformata del segnale $x(\omega)$ (mediante una FFT).
    \item Se ne calcola il modulo quadro $\left| x(\omega) \right|^2$.
    \item Si effettua una trasformata inversa (mediante una RFFT).
\end{itemize}
Se la lunghezza del segnale $x$ è $N$ allora per calcolarne la funzione di correlazione secondo la \ref{eq:Gt_init} è necessario effettuare $N^2$ operazioni, per calcolarla secondo la \ref{eq:G_inv} (quindi tramite la FFT) si effettuano $N\log(N)$ operazioni.
\subsection{Probabilità}%
\label{sub:Probabilità}
Possiamo ripensare una definizione assiomatica della probabilità.
\input{lezioni/tikz/lez_2_prob.tex}
Nella quale $\boldsymbol{x}$ è un evento, $A$ è un set di eventi possibili appartenente ad $\Omega$: l'insieme di tutti gli eventi possibili $(A \in \Omega)$.
\paragraph{Proprietà di $P$ }%
\label{par:Proprietà di P}
\begin{itemize}
    \item $P\left(A\right)\ge 0$.
    \item $P\left(\Omega\right) = 1$.
    \item $P\left(\cup_{i}^{} A_i \right) = \sum_{i}^{} P\left(A_i\right)$ con $A_i$ collezione di insiemi disgiunti numerabile.
    \item $P\left(\overline{A}\right) = 1- P\left(A\right)$.
    \item Se $\omega \in A \cup B$ con $A \cup B = 0$ $\implies$ $\omega\in A \ \lor \ \omega  \in B$.
\end{itemize}
\begin{defn}[Probabilità congiunta]
    Se $A \cap B \neq 0$ allora la probabilità congiunta di un evento $\omega$ è:
    \[
	P(A\cap B) = P(\omega \in A \ e \ \omega \in B)
    \]
\end{defn}
\begin{defn}[Probabilità condizionata]
    La probabilità che avvenga l'evento $A$ sapendo che è già avvenuto un evento $B$ è data da:
    \[
        P\left(A|B\right) = \frac{P\left(A \cap B\right)}{P\left(B\right)}
    .\] 
\end{defn}
Ovviamente si ha anche che:
\[
    P\left(A|B\right)P(B) = P(A)P\left(B|A\right)
.\] 
Prendiamo adesso un insieme $B_i$ di set di eventi:
\[\begin{aligned}
& B_i \cap B_j = \O \quad \forall i,j \\
& \bigcup_{i}^{} B_i = \Omega 
.\end{aligned}\]
Da queste ne deriva che, per il set $A$:
\[
    \begin{WithArrows}
	\bigcup_{i}^{}  \left(A \cap B_i \right) = A \cap \left(\bigcup_{i}^{}  B_i\right) = A \cap \Omega = A &
	\Arrow[jump=2,xoffset=0.5cm]{Utile per} \\
													       &\\
	\sum_{i}^{} P\left(A\cap B_i\right) = P\left(\bigcup_{i}^{} \left(A \cap B_i\right)\right) =  P(A) &
    \end{WithArrows}
.\] 
Per la probabilità congiunta si ha in generale che:
\begin{greenbox}{}
	\[
    		\sum_{i}^{} P\left(A|B_i\right)P(B_i) = \sum_{i}^{} P\left(A \cap B_i\right) = P(A) 
	.\]    
\end{greenbox}
\begin{defn}[Eventi indipendenti]
 Due eventi $x_A, x_B$ si dicono indipendenti se i set a cui appartengono $(A, B)$ rispettano la seguente:
\[
    P(B) P(A|B) = P(A\cap B) = P(A) P(B) 
.\]    
\end{defn}
\noindent
Questa fattorizzazione è valida in generale per eventi indipendenti:
\[
    P\left(\bigcap_i A_i\right) = \prod_i P(A_i) 
.\]    
\paragraph{Valor medio e distribuzione di probabilità}%
\label{par:Valor medio e distribuzione di probabilità}
Sia $R$ una variabile random funzione di un evento $\omega$, il valor medio di $R$ sarà:
 \[
    \left<R\right> = \sum_{\omega}^{} P(\omega) R(\omega) 
.\]    
Possiamo facilmente estendere la definizione al caso continuo, definiamo il set $A(\omega_0, d\omega_0)$ come l'insieme degli eventi $\omega$ tali che:
\[
    \omega  \in \left[\omega_0, \omega_0 + d\omega_0\right]
.\] 
La densità di probabilità di trovare un evento nel set $A(\omega_0, d\omega_0)$ è data da:
\[
    P(\omega_0) d\omega_0 \equiv P\left[A(\omega_0,d\omega_0) \right] \equiv P(\omega_0,d\omega_0) 
.\] 
Quindi il valor medio di $R$ nel continuo:
 \[
    \left<R\right> = \int\limits_{\omega\in \Omega} R(\omega) P(\omega) 
.\]    

\subsection{Limiti con variabili stocastiche}%
\label{sub:Limiti con variabili stocastiche}
Un problema al limite con una variabile stocastica $x$ è un problema del seguente tipo:
\[
    x = \lim_{n \to \infty} x_n \qquad x_n \in \Omega
.\] 
Dove $x_n$ è una serie di funzioni di variabile stocastica $\omega$, indicizzata da $n$ intero. \\
La variabile stocastica $\omega$ appartiene all'insieme degli eventi possibili $\Omega$
\begin{defn}[\textcolor{red}{Almost Certain Limit}]
 \[
    \lim^{\text{ac}}_{n \to \infty} x_n = x
    \qquad \text{se } \forall \omega \in \Omega: \
    \lim_{n \to \infty} x_n(\omega) = x
.\] 
Tale limite rispetta la proprietà:
\[
    P(\lim_{n \to \infty} x_n(\omega) =x) =1
.\] 
\end{defn}
\begin{exmp}[Farfalle]
    Alcune specie di farfalle vivono mediamente un giorno, prendiamo tutte le farfalle viventi che appartengono a questa specie (ed escludiamo quelle che devono ancora nascere).\\
    Se misuriamo la media del cibo consumato da questo campione ogni ora otteniamo una sequenza di numeri casuali.
    Tuttavia possiamo essere quasi sicuri che tale sequenza dopo 30 ore sarà 0 e rimarrà 0 per sempre.\\
    In questo esempio si hanno: 
    \begin{itemize}
        \item $x_n$ la sequenza di medie del cibo.
	\item $\omega$ Il cibo che una farfalla della specie mangia in un'ora.
	\item $x = 0$.
    \end{itemize} 
\end{exmp}
\begin{exmp}[Equazione stocastica]
    Prendiamo una equazione stocastica differenziale così costruita:
    \[
        dx = - \alpha x dt + bxd\omega
    .\] 
    In cui il termine $d\omega$ è un termine stocastico.\\
    I passi degli $x_n$ saranno definiti dalla equazione sopra:
    \[
        x_{n+1} = x_n - \alpha  x_n \Delta t + b x_n \Delta\omega_n
    .\] 
    Se ipotizziamo che la $x_n$ (variabile composta da termine stocastico e termine temporale)  nell'evoluzione si avvicini all'origine ($x_n = 0$) allora il termine stocastico in $\omega$ non può più contribuire alla equazione, in tal caso la convergenza avviene.
\end{exmp}
\begin{defn}[\textcolor{red}{Mean Square Limit}]
    \label{def:mslim}
    Se si ha:
    \[\begin{aligned}
	\lim_{n \to \infty} & 
	\left<\left(x_n(\omega) -x(\omega) \right)^2\right> =\\
			    &=\lim_{n \to \infty} 
			    \int  d\omega  P(\omega) 
			    \left[ x_n(\omega) -x(\omega) \right]^2 = 0
    .\end{aligned}\]
    Allora:
    \[
        \lim^{\text{ms}}_{n \to \infty} x_n = x
    .\] 
\end{defn}
\begin{defn}[\textcolor{red}{Limite in probabilità}] 
    \[
        \lim^{\text{P}}_{n \to \infty} x_n = x
    .\] 
    se vale che, $ \forall \epsilon  > 0$:
    \[
	\lim_{n \to \infty} P(\left|x_n-x\right| > \epsilon) = 0
    .\] 
\end{defn}
\noindent
Per capire cosa rappresenta il termine $P(\left|x_n - x\right|>\epsilon)$ introduciamo la funzione caratteristica:
\[
    \chi_\epsilon (t) = 
    \begin{cases}
	0 & \left|t\right|< \epsilon\\
	1 & \left|t\right|>\epsilon
    \end{cases}
.\] 

\usetikzlibrary{math}
\tikzmath{\x = 3; \y = 0;}
\begin{center}
\begin{tikzpicture}
     \draw[-stealth] (-\x,0) -- (\x,0) node[right]{$t$};
     \draw[-stealth] (0,0) -- (0,\x*2/3) node[above]{$\chi_\epsilon(t)$};
     \draw[thick] (-\x,\x/3) -- 
     		  (-\x/3, \x/3) -- 
		  (-\x/3, 0) node[below]{$-\epsilon$} --
		  (0,0) node[below]{$0$} -- 
		  (\x/3,0) node[below]{$\epsilon$} -- 
		  (\x/3,\x/3) -- 
		  (\x,\x/3);
\end{tikzpicture}
\end{center}
\noindent
Il termine di probabilità in questione è valutato proprio nel supporto di questa funzione:
\[
    P(\left|x_n-x\right|>\epsilon) = \int d\omega P(\omega) \chi_\epsilon (\left|x_n-x\right|) 
.\] 
\begin{defn}[\textcolor{red}{Limite in distribuzione}]
    Data una funzione di $x_n$: $f(x_n)$ si ha che questa converge a $f(x)$ in distribuzione se:
    \[
	\lim^{\text{dist}}_{n \to \infty}: \qquad \lim_{n \to \infty} \left<f(x_n)\right> = \left<f(x)\right>
    .\] 
\end{defn}
\begin{exmp}[Moto Browniano e moto a step]
    Prendiamo due moti con regole stocastiche differenti: un moto Browniano (passo del moto random) ed un moto casuale di passo unitario.
    Ipotizziamo che il corpo che effettua il moto (nei due casi) parta dall'origine.\\
    Le distribuzioni di probabilità dei fenomeni sono diverse, il valor medio del moto è invece nullo in entrambi i casi. Per questo motivo entrambi i moti tendono a 0 in distribuzione.
\end{exmp}
\noindent
Quest'ultimo limite è usato spesso "simulativamente", ovvero per la soluzione di equazioni differenziali stocastiche.\\
I limiti elencati in questa sezione non sono tutti indipendenti, infatti ($\implies$ = "implica" ) :
\[\begin{aligned}
    & \lim^{\text{ac}}_{n \to \infty} \implies  \lim^{\text{P}}_{n \to \infty} \\
    & \lim^{\text{ms}}_{n \to \infty} \implies  \lim^{\text{P}}_{n \to \infty} \\
    & \lim^{\text{P}}_{n \to \infty} \implies \lim^{\text{dist}}_{n \to \infty}  
.\end{aligned}\]


\clearpage
