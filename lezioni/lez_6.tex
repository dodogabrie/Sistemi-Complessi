\section{Random Walk}%
\label{sub:Lezione 6}
\mylocaltoc
\subsection{Modelli semplici di Random Walk}%
\label{sub:Random Walk}

Mettiamoci in una situazione unidimensionale, con un oggetto che può fare salti di ampiezza unitaria.
\input{lezioni/tikz/lez_6_random_walk.tex}
Possiamo analizzare due modelli di RW:
\begin{enumerate}
    \item Salto di $\pm 1$ ad un tempo casuale.
    \item Salto di $\pm 1$ ad un tempo $\tau$ fissato.
\end{enumerate}
Entrambi i casi descrivono processi Markoviani.
\subsubsection{1. Salto ad un tempo random.}%
\label{subsub:1. Salto ad un tempo random.}
L'equazione di Chapman-Kolmogorov in forma differenziale per il processo si scrive come:
\[\begin{aligned}
    \partial_{t}P\left(n,t|n',t'\right) = \left[ \ \right.&\omega\left(n|n+1,t\right)P\left(n+1, t|n',t'\right) +\\
                                             +& \omega\left(n|n-1,t\right)P\left(n-1, t|n',t'\right) + \\
					     -& \left. 2P\left(n,t|n',t'\right) \ \right]
.\end{aligned}\]
Facciamo chiarezza sui termini in equazione, prendiamo il primo nella parentesi quadra dopo l'uguale:
\[
    \omega\left(n|n+1,t\right)P\left(n+1, t|n',t'\right)
.\] 
Questo indica la probabilità di essere in $n+1$ (descritta dal termine $P$) e di fare un salto all'indietro (descritta dalla probabilità corrispondente $\omega$).\\
L'ultimo termine in parentesi indica la probabilità di essere in $n$ al tempo $t$, se ci troviamo in tal punto allora allo step successivo usciamo sicuramente fuori per costruzione del moto.\\
Imponendo che il rate di salto in avanti sia uguale a quello di salto all'indietro:
\begin{equation}
    \omega (n+1|n,t) = \omega (n-1|n,t) \equiv d \label{6_rate}
\end{equation}
Possiamo semplificare l'equazione del processo:
\begin{bluebox}{Chapman-Kolmogorov per RW 1.}
    \begin{equation}
\begin{aligned}
    \partial_{t}P\left(n,t|n',t'\right) = d\left[ \ \right.&P\left(n+1, t|n',t'\right) +\\
                                             +& P\left(n-1, t|n',t'\right) + \\
					     -& \left. 2P\left(n,t|n',t'\right) \ \right]
					     \label{eq:RW_1}
.\end{aligned}
    \end{equation}
\end{bluebox}
\noindent
Si risolve in trasformata:
\[
    G(s,t) = \left<e^{isn}\right> = \sum_{n}^{\infty} P\left(n,t|n',t'\right)e^{isn}
.\] 
Quando abbiamo un termine del tipo $P\left(n\pm 1|n',t'\right)$ basta scrivere:
\[
    e^{isn}P\left(n\pm 1, t|n',t'\right) = e^{\mp is} e^{is(n\pm 1)}P\left(n\pm 1, t|n',t'\right)
.\] 
Quindi inserendo nella equazione di CK:
\[
    \partial_{t}G(s,t) =d\left(e^{-is}+ e^{is}-2\right)G(s,t) 
.\] 
Si risolve per $G(s,t)$:
\[
    G(s,t) = \exp \left[\left(e^{is}+e^{-is}-2\right)td\right]G(s,0) 
.\] 
Andando a cercare la soluzione stazionaria si ha che:
\[
t\to \infty \implies s\to 0
.\] 
Questo per le relazioni tra spazio reale e trasformata: in sostanza stiamo assumendo i camminatori come oggetti reali, quindi se $\omega\to 0$ dev'essere necessariamente che $s\to 0$:
\[
    \omega  \sim sc
.\] 
Sviluppando la $G$ al secondo ordine in $s$ si ottiene:
\[
    G(s,t) = \exp(-s^2td)  \equiv e^{-s \sigma^2 /2}
.\] 
Quindi effettuando la trasformata inversa si ottiene una Gaussiana con larghezza $\sigma^2 = 2td$: la distribuzione si allarga nel tempo.
\subsubsection{2. Salto ad un tempo $\tau$ fissato}%
\label{subsub:2. Salto ad un tempo tau fissato}
In questo caso il tempo è una variabile discreta di passo $\tau$.
\begin{bluebox}{Equazione per il propagatore nel RW 2}
\begin{align}
    &P( n,(N+1) \tau |  n',N'\tau ) = \nonumber \\
			       & \frac{1}{2} \left[ P\left( n+1,N\tau |n',N'\tau \right) \right. +  \nonumber \\
			       & \quad + \left.  P\left(n-1,N\tau |n',N'\tau\right) \right] \label{eq:6_1}
.\end{align}
\end{bluebox}
\noindent
\begin{greenbox}{RW1 e RW2 equivalenti per scale piccole.}
 Se $\tau$ è piccolo rispetto a $N\tau$ il caso (2) diventa equivalente al caso (1).   
\end{greenbox}
\noindent
Definiamo il tempo $t' = N'\tau$ e riscriviamo l'espressione per la derivata di $P$ nel seguente modo:
\begin{equation}
\begin{aligned}
    P\left(n,(N+1) \tau|n',N'\tau\right)\simeq & P\left(n,N\tau|n',t'\right) + \\
					       & + \tau\partial_{t}P\left(n,N\tau|n',t'\right) \label{eq:6_2}
.\end{aligned}
\end{equation}
Si procede definendo il rate di salto come: 
\[
 d \equiv 1 /2\tau   
.\] 
Possiamo ottenere l'equazione \ref{eq:RW_1} sostituendo al termine a sinistra dell'uguale nella \ref{eq:6_1} l'espressione ottenuta nella \ref{eq:6_2} .\\
Risolviamo adesso la \ref{eq:6_1} con il metodo della funzione caratteristica ($G(s,t) = \left<e^{ins}\right>$ ):
\[
    G(s, (N+1)\tau) = \frac{1}{2}\left(e^{is}+ e^{-is}\right)G(s,N\tau) 
.\] 
Come condizione iniziale si impone che $G(s,0) = 1$.\\
In questo modo l'equazione in $G$ è una ricorsiva in $N$ che ha soluzione:
\[
    G(s,N\tau) = \left(\frac{1}{2}\left(e^{is}+e^{-is}\right)\right)^{N}
.\] 
A questo punto possiamo vedere che se $N\to \infty$ si ottiene una soluzione Gaussiana come nell'RW1 (mandare $N\to \infty$ significa limite stazionario).
\[
    \begin{cases}
        \tau N = t\\
	d = \dfrac{1}{2\tau}
    \end{cases}
    \implies  
    \frac{td}{N} = \frac{1}{2}
.\] 
\[
    G(s,N\tau) = \left[1 + \frac{td}{N}\left(e^{is}+ e^{-is}-2\right)\right]^N
.\] 
Sfruttando il limite notevole:
\[
    \lim_{x \to \infty} \left(1+\frac{\alpha}{x}\right)^{x} = e^{\alpha}
.\] 
Si ottiene:
\[
    G(s, N\tau) \xrightarrow[]{N \to \infty} G(s,t) = \exp\left[td\left(e^{is}+e^{-is}-2\right)\right]
.\] 
In conclusione è come se, aspettando abbastanza a lungo, la caoticità sul salto di $\pm 1$ contagiasse il clock di salto $\tau$ rendendo anch'esso caotico come nel caso RW1.\\
Nel proseguo distingueremo i due casi solo dove necessario vista la loro equivalenza a stazionarietà.

\subsubsection{Limite al continuo nei salti}%
\label{subsub:Limite al continuo}
Definiamo lo spazio percorso dal camminatore dopo $n$ step in un reticolo di passo $l$:
\[
    x = nl
.\] 
\input{lezioni/tikz/lez_6_random_walk_l.tex}
Quello che faremo sarà far il limite per $l\to 0$.\\
La trasformata si modifica per questo caso nel seguente modo:
\begin{equation}
\begin{aligned}
    \phi (s,t) = &\left<e^{isx}\right> = G(ls, t) =\\
		 & = \exp \left[\left(e^{ils} + e^{-ils} -2 \right)td\right]
		 \label{eq:6_continuo}
.\end{aligned}
\end{equation}
Dove ricordiamo che $d$ è il rate del processo definito dalla \ref{6_rate}.\\
Si studia adesso anche il caso stazionario, quindi dobbiamo effettuare entrambi i limiti:
\[\begin{aligned}
    &l\to 0\\
    &\tau\to 0
.\end{aligned}\]
Sviluppando nell'esponenziale della \ref{eq:6_continuo} ci si rende conto che sopravvive solo il termine:
\[
    \sim \exp\left(-s^2l^2td\right)
.\] 
Quindi la $G(ls, t)$ si annulla per $l \to 0$. Per rimediare a questo fatto è possibile supporre che il rate $d$ diverga in modo da bilanciare l'andamento di $l$.
\[
    D \equiv \lim \limits_{\substack{%
	         l \to 0\\
		  d \to \infty}} l^2d = \text{Finito}
.\] 
Fare il limite per il Rate $d\to \infty$ è lo stesso che fare il limite per $\tau\to 0$ poiché per definizione $d = 1 /2\tau$.\\
In conclusione otteniamo un andamento per $\phi$ Gaussiano:
\begin{bluebox}{Funzione caratteristica per RW nel limite continuo}
\[
    \phi (s,t) = \exp\left(-s^2tD\right)
.\]     
\end{bluebox}
\noindent
Quindi abbiamo anche che:
\begin{equation}
    \left<x^2\right> \sim  2tD \label{eq:6_mom_sec}
\end{equation}
\subsubsection{Random Walk e processi di Wiener}%
\label{subsub:Random Walk e processi di Wiener}
Si può dimostrare che per $l\to 0$ l'equazione che regola il propagatore $P$ è una Fokker-Plank (che regola anche i processi di Wiener). \\
Partiamo dalla Master Equation già scritta sopra:
\[\begin{aligned}
    \partial_{t}P(n) = d\left(P(n+1) + P(n-1) -2 P(n) \right)
.\end{aligned}\]
Sviluppando in $l=0$ si ha:
\[\begin{aligned}
    &P(n+1) = P(n) + \partial_{x}P(n) l + \frac{1}{2}\partial^2_{x^2} l^2P(n) \\
    &P(n+1) = P(n) - \partial_{x}P(n) l + \frac{1}{2}\partial^2_{x^2} l^2P(n)
.\end{aligned}\]
E reinserendo nella equazione per $P$ si ha:
\[
    \partial_{t}P(n) = dl^2 \partial^2_{x^2} P(n) 
.\] 
Che è appunto una Fokker-Plank.

\subsection{Random Walk di Weierstrass}%
\label{sub:Random Walk di Weierstrass}
Questo RW è più complesso dei primi due, si basa su alcuni parametri che ne determinano il passo ed il rate: ($N$, $b$).\\
Adesso anziché fare salti fissi di $l$ si fanno salti $J_n$ con rate $R_n$ che variano al variare dell'intero $n$. $J_n$ e $R_n$ sono così definiti:
\[
    J_n = \left(N^{n}+1\right)l \qquad R_n = \frac{\gamma}{b^n} \qquad b,N > 1
.\] 
\[
    n \in \left[0\ldots\infty\right]
.\] 
\input{lezioni/tikz/lez_6_random_walk_wier.tex}
Possiamo considerare $\gamma$ come il parametro corrispondente a $d$ della sezione precedente.
Quindi ad esempio si può avere:
\begin{itemize}
    \item Salto di $l$ con rate $\gamma$. 
    \item Salto di $\left(N+1\right)l$ con rate $\gamma  / b$.
    \item Salto di $\left(N^2+1\right)l$ con rate $\gamma /b^2$.
\end{itemize}
Come conseguenza salti più lunghi avranno rate più bassi (quindi saranno meno frequenti).\\
\subsubsection{Master Equation per il RW di Weierstrass}%
\label{subsub:Master Equation per il RW di Weierstrass}
\[\begin{aligned}
    \partial_{t}P\left(n,t|n',t'\right) = &\sum_{i=0}^{\infty} 
    \frac{\gamma}{b^{i}} \left[P\left(n+(N^{i}+1) ,t|n',t'\right) \right. + \\
		    & \qquad \quad + \left. P\left(n-(N^{i}+1) ,t|n',t'\right)\right] + \\
		     - &2 \sum_{i=0}^{\infty} \left(\frac{\gamma}{b^{i}}\right) P\left(n,t|n',t'\right)
.\end{aligned}\]
La prima sommatoria tiene di conto di tutti i punti che possono arrivare da distanze diverse. La seconda sommatoria invece tiene conto di quelli che sono già nel punto e scappano via.\\
L'equazione descrive un processo a salti, di conseguenza il moto in questione è Markoviano. Come per gli altri RW risolviamo con la funzione caratteristica.
\[
    G(s,t) = \left<e^{isn}\right> = \sum_{n}^{\infty} e^{isn}P(n,t|n',t') 
.\] 
La master equation si riscrive come:
\[\begin{aligned}
    \partial_{t}G(s,t) = \gamma &\left[e^{is}\left( 1 + \sum_{n=0}^{\infty} \frac{e^{isN^{n}}}{b^{n}} \right) + \right.\\  
				& \ \ \left. + e^{-is}\left( 1 + \sum_{n=0}^{\infty} \frac{e^{-isN^{n}}}{b^{n}} \right) + \right.\\
				& \qquad \qquad \qquad \qquad \ \left.- 2 \sum_{n=0}^{\infty} \frac{1}{b^n} \right]G(s,t) 
.\end{aligned}\]
Possiamo compattare la scrittura con la notazione:
\[
    f(s) \equiv \left[e^{is}\left( 1 + \sum_{n=0}^{\infty} \frac{e^{isN^{n}}}{b^{n}} \right) + C.C - 2 \sum_{n=0}^{\infty} \frac{1}{b^n} \right]
.\] 
Che ci permette di esprimere direttamente il risultato:
\begin{bluebox}{Funzione caratteristica per il RW di Weierstrass}
\[
    G(s,t) = \exp\left(tf(s)\right)G(s,0) 
.\]     
\end{bluebox}
\noindent
\subsubsection{Limite stazionario}%
\label{subsub:Limite stazionario}
Vediamo se anche in questo caso mandando $t\to \infty$ si ottiene una Gaussiana come nei casi RW1 e RW2.\\
Sviluppando la $G$ per $s\to 0$ si ottiene che molti termini polinomiali si semplificano, rimane soltanto la seguente:
\[
    G(s,t) = \exp\left(-ts^2 \sum_{k=0}^{\infty} \left(\frac{N^2}{b}\right)^k\right)
.\] 
Il coefficiente di diffusione $D$ è rappresentato in questo caso dalla sommatoria:
\[
    D \to \sum_{k=0}^{\infty} \left(\frac{N^2}{b}\right)^k\
.\] 
Quello che si scopre è quindi che il parametro $N^2 /b$ decide se il processo sarà Gaussiano o no, infatti:
\begin{redbox}{}
\begin{itemize}
    \item Se $N^2 /b< 1$ abbiamo una serie geometrica all'esponenziale che ci riconduce ad una forma Gaussiana.
    \item Se $N^2 /b > 1$ la sommatoria diverge, il processo resta Markoviano ma non vale più il teorema del limite centrale (poiché la varianza diverge).
\end{itemize}
\end{redbox}
\noindent
Visto che il momento secondo è proporzionale a $D$ (eq. \ref{eq:6_mom_sec}) se ne conclude un processo con $N^2 /b > 1$ ha varianza infinita.\\
La cosa interessante è che abbiamo scoperto un processo random che al limite non diventa una Gaussiana \footnote{il momento secondo deve essere definito nelle ipotesi per il teorema del limite centrale\ldots}

\subsection{Random Telegraph}%
\label{sub:Random Telegraph}
Il RT è un processo random che coinvolge un sistema a due stati (o livelli):
\input{lezioni/tikz/lez_6_random_tele.tex}
Il processo è descritto dalle equazioni differenziali:
\[\begin{aligned}
    &\partial_{t}P\left(a,t|x,t_0\right) = -\lambda P\left(a,t|x,t_0\right) + \mu P\left(b,t|x,t_0\right)\\
    &\partial_{t}P\left(b,t|x,t_0\right) = \lambda P\left(a,t|x,t_0\right) - \mu P\left(b,t|x,t_0\right)
.\end{aligned}\]
In cui $x$ può essere $a$ oppure $b$.\\
In questo caso c'è anche una terza equazione per la normalizzazione del processo:
\[
    P\left(a,t|x,t_0\right)+ P\left(b,t|x,t_0\right) = 1
.\] 
Si scelgono le condizioni iniziali:
\[
    P\left(x,t_0|x',t_0\right) = \delta_{xx'}
.\] 
E quello che si ottiene risolvendo le equazioni differenziali è:
\begin{equation}
    P\left(x', t|x,t_0\right) =  \frac{\omega (x') }{R} + e^{-R (t-t_0)}\left(\frac{\lambda}{R}\delta_{ax} + \frac{\mu}{R}\delta_{bx}\right)
    \label{eq:6_RT}
\end{equation}
In cui $R$ è la somma dei due rate:
\[
    R = \mu +\lambda
.\] 
Mentre la funzione $\omega (x')$ differenzia i casi con $x'=a$ e $x'=b$:
\[
    \omega(x') =
    \begin{cases}
        \lambda  \quad \text{ se } x' = a\\
        \mu  \quad \text{ se } x' = b
    \end{cases}
.\]
Il primo termine nella \ref{eq:6_RT} è il termine stazionario. Il secondo termine invece decade esponenzialmente in $t$, il termine con le  $\delta$  a moltiplicare deriva dalle condizioni iniziali inserite.
\[\begin{aligned}
    \left<x(t) | \left[x_0,t_0\right]\right> = & \sum_{x = a,b}^{} xP\left(x,t|x_0,t_0\right) = \\
					      = &\mathcal{R} + \left(x-\mathcal{R}\right)e^{-R(t-t_0)}
.\end{aligned}\]
Dove $\mathcal{R}$ è il Rate ridotto:
\[
\mathcal{R} = \frac{ a\mu + b\lambda}{\lambda + \mu}; \qquad R = \mu + \lambda
.\] 
Si può anche calcolare la varianza di $x(t)x(s)$, senza esplicitare i conti si ha:
\[\begin{aligned}
    \text{var}(x(t) x(s) ) = & \left<x(s) x(t) \right> - \left<x(s)\right>\left<x(t) \right> = \\
			     =& \frac{\left(a-b\right)^2\lambda\mu}{\mu +\lambda}e^{-R(t-t_0) }
.\end{aligned}\]
\begin{bluebox}{RT e OU}
    Le dipendenze dal tempo di media e varianza calcolate per il processo di Ornstein-Uhlenback sono le stesse che per il processo di Random Telegraph.
\end{bluebox}
\noindent
Per questo motivo spesso si preferisce studiare alcuni processi con il random telegraph che, analiticamente, permette di trovare la soluzione in modo più semplice.
\clearpage
