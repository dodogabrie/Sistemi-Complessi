\section{Introduzione agli Integrali stocastici}%
\label{sub:Lezione 7}
\mylocaltoc
\subsection{Integrali stocastici}%
\label{sub:Integrali stocastici}
Sia $x$ una variabile stocastica, il differenziale di questa variabile lo definiamo come:
\begin{equation}
    dx = d\omega (t) \label{eq:6_int}
\end{equation}
Ipotizziamo che il processo stocastico sia un processo di Wiener, in tal caso:
\[
    P(d\omega) \sim \exp\left(-\frac{\left(d\omega\right)^2}{dt}\right)
.\] 
Con $dt$ differenziale temporale.\\
Prendiamo allora una funzione $G(t)$, vogliamo definire cosa significa calcolare l'integrale di $G(t)$ se la misura è stocastica ($d\omega (t))$.
\begin{figure}[H]
    \centering
    \incfig{lez_6_int}
    \caption{\scriptsize Funzione $G(t)$ con punti stocastici $\omega_i$, $\Delta\omega_i$ è la distanza sull'asse $y$ tra il punto $\omega_{i-1}$ e $\omega_i$.}
    \label{fig:lez_6_int}
\end{figure}
\noindent
Definiamo l'integrale di $G(t)$ come mean-square limit:
\begin{redbox}{Integrale stocastico}
\[
    \int_{t_0}^{t_n} G(s) d\omega (s) \equiv \lim^{\text{ms}}_{n \to \infty} \sum_{i}^{} G(\tau_i) \left[\omega (t_i) - \omega (t_{i-1}) \right]
\] 
Il valore dell'integrale dipende dalla scelta dei $\tau_i$.
\end{redbox}
\noindent
Il limite in questione è definito analogamente a quanto definito nella \ref{def:mslim}: sia $I$ il risultato dell'integrale, allora deve valere che:
\[
    \lim_{n \to \infty} \left<\left(I -  \sum_{i}^{} G(\tau_i) \left[\omega (t_i) - \omega (t_{i-1}) \right]\right)^2\right> = 0
.\] 
\'E interessante utilizzare come $G(t)$ il processo di Wiener stesso per vedere cosa succede:
\[
    G(t) = \omega (t) 
.\]
Inoltre definiamo gli step $\tau_i$ come:
\begin{equation}
    \tau_i = t_{i-1} + \alpha (t_i - t_{i-1}) \qquad 0 <\alpha <1 \label{eq:tau}
.\end{equation}
Valutiamo la sommatoria all'interno della definizione:
\[\begin{aligned}
    \left<S_n\right> =& \sum_{i=0}^{n} \left<\omega (\tau_i)\left[ \omega (t_i) - \omega (t_{i-1})  \right] \right>=\\
		      & = \sum_{i=0}^{n} \left<\omega (t_{i-1} +\alpha (t_i-t_{i-1}) ) \omega(t_i) \right> + \\
		  & \qquad \qquad - \left<\omega (t_{i-1} +\alpha (t_i-t_{i-1}) ) \omega(t_{i-1}) \right>
.\end{aligned}\]
Ricordando che nei processi di Wiener vale:
\[
    \left<\omega (t) \omega (s) \right> = \text{min}(s,t) 
.\] 
Rimane soltanto:
\[\begin{aligned}
    \left<S_n\right> =& \sum_{i=0}^{n} t_{i-1} + \alpha (t_i-t_{i-1}) -\sum_{i=0}^{n} t_{i-1} = \\
		      & =\alpha(t_n-t_0) 
.\end{aligned}\]
Di conseguenza con la scelta \ref{eq:tau} per i $\tau_i$ contano solo l'istante finale ed iniziale. Quindi anche facendo il limite per $\Delta t \to 0$ (quindi $n \to \infty$) il limite dipende sempre da $\alpha$. \\
Quando $\alpha =0$ l'integrale si annulla, mentre quando $\alpha =1$ l'integrale è l'intervallo temporale.\\
La vera domanda da porsi è quale sia il giusto valore di $\alpha$\ldots
\subsection{Integrale di $\hat{\text{I}}$to e di Stratonovich}%
\label{sub:Integrale di Ito e di Stratonovich}
\subsubsection{Integrale di $\hat{\text{I}}$to}%
\label{subsub:Integrale di Ito}
$\hat{\text{I}}$to è un matematico Giapponese, integrare con $\hat{\text{I}}$to implica scegliere $\tau_i$ all'inizio dell'intervallo.
\begin{bluebox}{Integrale di $\hat{\text{I}}$to}
    \[
        \alpha  = 0
    .\] 
    \[
	\tau_i = t_{i-1}
    .\] 
\end{bluebox}
\noindent
Le somme parziali con questo integrale si scrivono come:
\[
    S_n = \sum_{i}^{} \omega (t_{i-1}) \left[\omega (t_i) -\omega (t_{i-1}) \right]
.\]
L'integrazione di $\hat{\text{I}}$to forma una \texttt{Martingala}.
\paragraph{Martingala}%
\label{par:Martingala}
Dato un set di variabili stocastiche:
\[
    \left\{x_i\right\}: E(\left|x_i\right|) < \infty
.\] 
\[
    \left\{x_i\right\} \text{ è marting.} \iff
    E(x_{n+1}|x_1,\ldots,x_n) = x_n
.\] 
Con $E$: valore di aspettazione.\\
Possiamo notare che il processo di Wiener realizza una martingala perché rispetta questa proprietà.\\
Il calcolo di $\hat{\text{I}}$to è anche non anticipante:
\begin{redbox}{Funzione non anticipante}
    $G(t)$ è non anticipante se è indipendente dall'incremento $\omega (t) - \omega (s) $ $\forall t, s$.
\end{redbox}
\noindent
\begin{exmp}[Esempi di funzioni non anticipanti]
    Dato un processo di Wiener $\omega (t)$ tutte le seguenti funzioni sono non anticipanti:
    \begin{itemize}
	\item $\omega (t) $.
	\item $\int dt f(\omega (t) ) $.
	\item $\int d\omega f(\omega (t) ) $.
    \end{itemize}
\end{exmp}
\noindent
\subsubsection{Integrale di Stratonovich}%
\label{subsub:Integrale di Stratonovich}
Stratonovich era un fisico russo, integrare con Stratonovich implica scegliere il centro dell'intervallo.
\begin{bluebox}{Integrale di Stratonovich}
    \[
        \alpha = \frac{1}{2}
    .\] 
    \[
        \tau_i = \frac{1}{2}\left(\tau_{i-1}+ \tau_i\right)
    .\] 
\end{bluebox}
\noindent
Le somme parziali in questo caso si scrivono come:
\[
    S_n = \sum_{i}^{} \omega\left(\frac{t_i + t_{i-1}}{2}\right)\left[\omega (t_i) -\omega (t_{i-1}) \right]
.\] 
L'integrale di Stratonovich ha caratteristiche analoghe a quello che si usa normalmente in fisica, infatti si applica bene con funzioni "morbide".

\begin{exmp}[]
    \[
	\int_{0}^{t} \omega (t) dt = 
	\begin{cases}
	    \dfrac{\omega^2(t)}{2}-\dfrac{\omega^2(0)}{2} = \dfrac{t}{2} & \text{ Strato}\\
	    \sum_{}^{} \omega_{i-1}\left(\omega_i-\omega_{i-1}\right) = 0 & \text{ }\hat{\text{I}}\text{to}
	\end{cases}
    \] 
\end{exmp}
\noindent

\subsection{Incremento stocastico e temporale.}%
\label{sub:Relazione tra l'incremento stocastico e l'incremento temporale.}
Dato $\omega$ processo di Wiener, allora vale la seguente:
\begin{greenbox}{}
\[
    \left(d\omega\right)^2\sim dt
.\] 
\end{greenbox}
\noindent
Questo significa che $d\omega$  è continuo ma non è differenziabile, come accennato nella Sezione \ref{sub:Processo di Wiener} per i processi di Wiener.\\
Tutti gli ordini più alti dell'incremento si annullano:
\[
    d\omega^{N+2} \sim 0 \qquad \forall N>0
.\] 
Più formalmente, consideriamo il seguente integrale calcolato con il metodo di $\hat{\text{I}}$to:
\[\begin{aligned}
    \int\left(d\omega\right)^{2+N}G(t) = \lim^{\text{ms}}_{n \to \infty} \sum_{i=0}^{n} G_{i-1} (\Delta\omega_i)^{2+N} 
.\end{aligned}\]
In cui $\Delta\omega_i = \omega_i - \omega_{i-1}$. Dimostriamo che questo integrale vale:
\[
  \lim^{\text{ms}}_{n \to \infty} \sum_{i=0}^{n} G_{i-1} (\Delta\omega_i)^{2+N} = 
  \begin{cases}
      \int dtG(t) & N=0\\
      0          & N>0 
  \end{cases}
\] 
Partiamo con l'esprimere il risultato per $N = 0$, quindi vogliamo dimostrare che:
\begin{equation}
    \int G(t) \left(d\omega\right)^2 = \int G(t) dt
    \label{eq:rel_dwdt_start}
\end{equation}
In termini di $\hat{\text{I}}$to il risultato dell'integrale si esprime come: 
\[
    \int G(t) dt = \lim_{n \to \infty} \sum_{i = 0}^{n} G_{i-1} \Delta t_i
.\] 
Dimostrando la relazione \ref{eq:rel_dwdt_start} si ha la tesi. Per farlo utilizziamo la definizione di limite m-s (la quantità sotto definita $I$ deve tendere a $0$): 
\[\begin{aligned}
    I &= \lim_{n \to \infty} \left<\left[G_{i-1} \left(\Delta\omega_i^2 - \Delta t_i\right)\right]^2\right> = \\
      &= \lim_{n \to \infty} \left<\sum_{i = 0}^{n} G_{i-1}^2\left(\Delta\omega_i^2-\Delta t_i\right)^2\right> +  \\
      & \quad + 2 \sum_{i > j}^{n} \left<G_{i-1}G{j-1} \left(\Delta\omega^2_j-\Delta t_j\right)\left(\Delta\omega_i^2 - \Delta t_i\right)\right>
.\end{aligned}\]
I due termini all'interno della prima sommatoria (su $i = 0 \to \infty$) sono indipendenti perché il processo è non anticipante, lo stesso vale per la seconda sommatoria con il termine $\left(\Delta\omega^2_i - \Delta t_i\right)$ e tutti i restanti a moltiplicare. Di conseguenza si possono mediare separatamente i termini indipendenti.\\
Esplicitiamo la relazione $\left<\left(\Delta\omega_i^2 - \Delta  t_i\right)^2\right>$ ricordando la eq. \ref{eq:var_wiener}:
\begin{equation}
    \left<\Delta\omega_i^2\right> = \Delta t_i
    \label{eq:rem_wiener}
\end{equation}
Ed anche la eq. \ref{eq:cum4_gauss}:
\[
\left<\Delta\omega^4_i\right> = 2\left(\sigma^2\right)^2 = 3 \Delta t_i^2
.\] 
Possiamo esplicitare i vari termini nel seguente modo:
\[\begin{aligned}
    \left<\left(\Delta\omega_i^2 -\Delta t_i\right)^2\right> &= \left<\Delta\omega_i^4\right> - 2\Delta t_i\left< \Delta\omega_i^2\right> + \Delta t_i^2 = \\
    &=3\Delta t_i^2 - 2\Delta t_i^2 + \Delta t_i^2 = 2 \Delta t^2_i
.\end{aligned}\]
I termini della seconda sommatoria sono tutti nulli perché:
\[
    \left<\left(\Delta\omega_i^2-\Delta t_i\right)\right> = \Delta t_i - \Delta t_i = 0 
.\] 
Per via della eq. \ref{eq:rem_wiener}. In conclusione il limite vale:
\[
    \lim_{n \to \infty} 2\sum_{i = 0}^{n} \left<G_{i-1}^2\right> \Delta t_i^2 = 0
.\] 
Perché $\Delta t_i^2$ tende a $0$ con $n\to\infty$.\\
Quindi è dimostrata la relazione \ref{eq:rel_dwdt_start} (proprio per la definizione di limite m-s) e di conseguenza si ha l'andamento atteso:
\begin{redbox}{}
    \begin{equation}
	d\omega  \sim O(dt^{1 /2}) \label{eq:6_order}
    \end{equation}
\end{redbox}
\noindent
\subsubsection{Applicazione: Differenziale di una funzione}%
\label{subsub:Applicazione: Differenziale di una funzione}
Prendiamo una funzione del tempo e del processo di Wiener $f\left[\omega,t\right]$, Visto che vale la \ref{eq:6_order} quando se ne effettua il differenziale i termini di ordine più basso sono i seguenti ($\left(d\omega\right)^2 \sim dt$):
\begin{bluebox}{Differenziale di una funzione}
    \[
	df\left[\omega,t\right] = \left[\frac{\partial f}{\partial t} + \frac{1}{2}\frac{\partial ^2 f}{\partial \omega^2} \right]dt + \frac{\partial f}{\partial \omega} d\omega
    .\] 
\end{bluebox}
\noindent
Questa struttura per il differenziale di una funzione è profondamente legata alla formula di $\hat{\text{I}}$to.
\subsection{Formula di $\hat{\text{I}}$to}%
\label{sub:Formula di ITO}
Supponiamo di avere una SDE della seguente forma:
\[
    dx = a(x,t) dt + b(x,t) d\omega
.\] 
La soluzione formale è del seguente tipo:
\[
    x(t) = x_0 + \int_{t_0}^{t} a(x,s) ds + \int_{t_0}^{t} b(x,s) d\omega (s)   
.\] 
Supponiamo che esista una ed una sola soluzione non anticipante
\footnote{Le ipotesi per cui vale sono negli appunti (saltate a lezione)}. \\
Data una funzione $f(x,t)$ della soluzione $x$ della SDE, il differenziale di $f(x, t$ all'ordine più basso si esprime tramite la formula di $\hat{\text{I}}$to.
\begin{redbox}{Formula di $\hat{\text{I}}$to}
    \[\begin{aligned}
	df(x,t) = 
	\left[\frac{\partial f}{\partial t} + 
	a \frac{\partial f}{\partial x} +
        \frac{1}{2}b^2 \frac{\partial ^2 f}{\partial x^2} \right] dt +
	b\frac{\partial f}{\partial x} d\omega 
    .\end{aligned}\]
    con $dx = adt + bd\omega$.
\end{redbox}
\noindent
L'utilità della formula è che ci permette di fare cambi di variabili con funzioni dipendenti da una variabile casuale.

\subsection{Integrale di una SDE}%
\label{sub:Integrale di una SDE}
Prendiamo una SDE (Stochastical Differential Equation) del seguente tipo:
\begin{equation}
    dx = f(x) dt + g(x) d\omega
    \label{eq:sde}
\end{equation}
Con $\omega$ processo di Wiener. \\
Nell'equazione abbiamo una parte deterministica ($f(x) dt$) ed una stocastica ($g(x)d\omega$).
\begin{figure}[H]
    \centering
    \incfig{lez_7_int}
    \caption{\scriptsize La linea rappresenta l'incremento della parte deterministica, in alto abbiamo invece il processo stocastico che discosta la $x$ dalla parte di funzione deterministica (come un rumore sovrapposto al segnale).}
    \label{fig:lez_7_int}
\end{figure}
\noindent
Abbiamo detto che formalmente possiamo integrare nel seguente modo (con $h$  passo di integrazione):
\[
    x_h - x_0 = \int_{0}^{h}  f(x(s) ) ds + \int_{0}^{h} g(x(s)) d\omega
.\] 
La formalità dell'espressione deriva dal fatto che le funzioni $f$ e $g$ dipendono da $x$, quindi non possiamo semplicemente risolvere questo integrale.
\subsubsection{Soluzione perturbativa}%
\label{subsub:Soluzione perturbativa}
Se prendiamo un passo di integrazione $h$ piccolo, possiamo sviluppare $f$ e $g$ attorno al punto $x_0$:
\[\begin{aligned}
    f(x_s)   &=f_0 + f'_0\delta x_s + \frac{1}{2}f''_0(\delta x_s) ^2 \\
    g(x_s)   &= g_0 + g'_0\delta x_s + \frac{1}{2}g''_0(\delta x_s) ^2 
.\end{aligned}\]
Con $\delta x_s = x_s-x_0$. Sostituendo nella equazione per la soluzione formale e tenendo solo l'ordine più basso si ha:
\begin{equation}
    \delta x_h = \int_{0}^{h} f_0ds + \int_{0}^{h} g_0d\omega  = f_0h + g_0  \int_{0}^{h} d\omega 
    \label{eq:int_stocastico_init}
\end{equation}
Al secondo termine della eq. \ref{eq:int_stocastico_init} vi è un integrale stocastico che, nel caso di un processo di Wiener, può essere valutato numericamente in modo semplice.
\paragraph{Soluzione numerica di integrale stocastico per processo di Wiener}
Data una SDE come in equazione \ref{eq:sde} con $d\omega$ processo di Wiener la soluzione del corrispettivo integrale può essere espressa (secondo lo sviluppo perturbativo di cui sopra) sotto forma di sequenza $\left\{x_n\right\}$ valutata tramite una procedura algoritmica. Noto l'elemento $x_n$ i passaggi per il calcolo del suo successivo $x_{n+1}$ sono i seguenti:
\begin{enumerate}
    \item Valutare la $f$ e la $g$ nel punto $x_n$.
    \item Estrarre un valore $z$ secondo la distribuzione del processo $\int d\omega$.
    \footnote{caratterizzeremo meglio tale distribuzione sotto}
    \item Mettere tutto insieme nel calcolo dello step $n+1$: $x_{n+1} = f(x_n)h + g(x_n) z$ 
\end{enumerate}
Il procedimento funziona perché l'integrale:
\[
    \int_{0}^{h} d\omega 
.\] 
\'E la somma di variabili Gaussiane, di conseguenza è anch'esso un processo con distribuzione Gaussiana:
\[
    Z_1(h) \equiv \int_{0}^{h} d\omega 
.\]
Vediamo le proprietà di $Z_1$:
\[
    \left<Z_1(h)\right> = \int_{0}^{h} \left<d\omega\right> = 0
.\] 
Poiché il processo di Wiener ha media nulla.
\[\begin{aligned}
    \left<Z^2(h) \right> = &\left<\int_{0}^{h} d\omega_s \int_{0}^{h} d\omega_t \right> = \\
			   &=\left<\sum_{i}^{} \left(\omega_i-\omega_{i-1}\right) \sum_{J}^{} \left(\omega_J-\omega_{J-1}\right)\right> = \\
			   &= \sum_{i}^{} \sum_{J}^{} \Delta t\delta_{iJ} = h
.\end{aligned}\]
Dove per risolvere si è usato che se $i \neq j$ i due incrementi sono indipendenti, quindi la media del loro prodotto è nulla. Inoltre si è usata l'uguaglianza dimostrata per i processi di Wiener:
\[
    \left<\Delta\omega^2\right> = \Delta t
.\] 
Se ne conclude che la variabile $Z_1$ è una Gaussiana a media nulla e con varianza $\sqrt{h}$:
\[
    Z_1 \in G(0,\sqrt{h}) 
.\] 
Operativamente possiamo generare un numero random tra $0$ e $1$:
\[
    Y_1(i) \in G(0,1) 
.\] 
Ed ottenere la variabile da moltiplicare a $g_0$ con:
\[
    Z_1(h) = \sqrt{h} Y_1(i) 
.\] 
Da questa distribuzione è possibile estrarre il valore stocastico $z$ per il procedimento algoritmico.
\paragraph{Correzione di $\hat{\text{I}}$to o Stratonovich}%
\label{par:Correzione di ito o Stratonovich}
L'equazione risultante per l'incremento $\delta x_h$ è:
\begin{equation}
\delta x_h = f_0 h + g_0Z_1(h) 
\label{eq:deltax_error}
\end{equation}
Nell'equazione \ref{eq:deltax_error} il primo termine a destra dell'uguale è di ordine $h$ mentre il secondo è di ordine $\sqrt{h}$ (poiché si parla di processo di Wiener). \\
Risulta quindi necessario capire se ci siamo persi dei termini di ordine $h$  nella parte di sviluppo stocastico.\\
Possiamo prendere la soluzione perturbativa al primo ordine e inserirla nuovamente all'interno dello sviluppo.\\
Ci limitiamo inoltre ad inserire solo il termine all'ordine più basso ($g_0Z_1(h)$) poiché il termine con $f_0$  darebbe sicuramente contributi di ordine superiore.
\[
    \delta x_s^{(1 /2)} = g_0Z_1(h) = g_0  \int_{0}^{h} d\omega 
.\] 
\[\begin{aligned}
    \delta x_t =& \int_0^t \left(f_0 + f_0' \delta x_s^{1 / 2}\right)ds + \int_0^t \left(g_0 + g_0' \delta x_s^{1 / 2}\right)d\omega_s = \\
    =& \int_{0}^{t} \left(f_0 + f'_0 g_0\int_{0}^{s}d\omega_r  \right) ds + \\
		 & + \int_{0}^{t} \left(g_0+ g'_0 g_0 \int_{0}^{s} d\omega_r\right)d\omega_s  \sim \\
    \sim & \left(O(t) + O(t^{3 / 2}) \right) + \left(O(t^{1 / 2}) + O(t)\right)
.\end{aligned}\]
L'unico nuovo contributo di ordine $t$ deriva dall'ultimo termine dell'integrale stocastico, tale termine è del tipo:
\[
    \int_{0}^{t} \left(\int_{0}^{s} d\omega_r\right) d\omega_s = \int_{0}^{t} \omega_sd\omega_s 
.\] 
Ne risulta che, all'ordine $t$, il calcolo dell'integrale dipende dalla scelta del parametro di discretizzazione $\tau$ ovvero dal calcolo di $\hat{\text{I}}$to o Stratonovich. 
\begin{bluebox}{}
    L'evoluzione dell'equazione differenziale stocastica dipende dalla scelta del metodo di integrazione.
\end{bluebox}
\[
  \int_{0}^{t} \omega_sd\omega_s =
  \begin{cases}
      \dfrac{\omega_t^2}{2} & \text{Strato}\\
      \dfrac{1}{2}\left(\dfrac{\omega_t^2}{2} - t\right) & \hat{\text{I}}\text{to}
  \end{cases}
\] 
In entrambi i casi si ottiene un termine $O(h)$, quindi:
\begin{redbox}{}
    \begin{equation}
    \delta x_h = 
    g_0Z_1(h) +
    f_0h + 
    \frac{g_0g'_0}{2}\cdot \alpha (\hat{\text{I}}, S) 
    \label{eq:int_stocastico_fin}
    \end{equation}
Con $\alpha (\hat{\text{I}}, S)$ data da:
\[
    \alpha (\hat{\text{I}}, S) = 
    \begin{cases}
	Z_1^2(h) & \text{Strato}\\
	Z_1^2(h) - h & \hat{\text{I}}to
    \end{cases}
\]    
\end{redbox}
\noindent
\subsubsection{Uguaglianza tra i due metodi}%
\label{subsub:Uguaglianza tra i due metodi}
L'equazione \ref{eq:int_stocastico_fin} descrive un integratore di ordine più basso possibile, tuttavia di fronte a casi di studio reali c'è spesso la necessità di utilizzare metodi di integrazione di ordine più elevato. Se il processo fisico in analisi segue il calcolo di Stratonovich allora si possono utilizzare tutti gli algoritmi noti (per esempio i Runge-Kutta), se il processo va trattato con $\hat{\text{I}}$to in linea di principio questo non è possibile.\\
Ci viene in aiuto il seguente cambio di variabili:
\[
    dx = \left(f-\frac{1}{2}gg'\right)dt + gd\omega \equiv \tilde{f} dt + g d\omega
.\] 
in questo modo si ha che i due $\delta x_h$ ($\hat{\text{I}}$to e Stratonovich) si eguagliano poiché il termine aggiunto va a compensare il termine che subentra con l'integrale di $\hat{\text{I}}$to. Di conseguenza la formula per l'incremento si modifica nel seguente modo:
\[
    \delta x_h = 
    g_0Z_1(h) +
    \tilde{f}_0h + 
    \frac{g_0g'_0}{2}\cdot Z_1^2(h)
\]
L'importanza di questo "cambio di variabili" è che ci autorizza ad utilizzare l'approccio di Stratonovich anche per sistemi che fisicamente andrebbero trattati con $\hat{\text{I}}$to. \\
\subsection{Algoritmo di Heun}%
\label{sub:Algoritmo di Heun}
L'algoritmo di Heun è spesso utilizzato per integrare le SDE, si tratta di un algoritmo a 3 step:
\[\begin{aligned}
    & \tilde{x}_1 = x_0 + Z_1g_0 + f_0 h  + \frac{1}{2}g_0g'_0 Z_1^2\\
    & x_1 = x_0 + Z_1 g(\tilde{x}_0) + f(\tilde{x}_0)  + \frac{1}{2}g(\tilde{x}_0) g'(\tilde{x}_0) Z_1^2\\
    & x_h = \frac{1}{2}\left(x_1+ \tilde{x}_1\right)
.\end{aligned}\]
Dove la $Z_1$ viene calcolata una sola volta per i tre step descritti sopra (una unica estrazione).\\
L'algoritmo di Heun corrisponde a fare un primo step di predizione ed un successivo step di correzione.
\clearpage
