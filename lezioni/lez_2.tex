\section{Richiami di Teoria della probabilità}%
\label{sub:Lezione 2}
\mylocaltoc

\subsection{Correlazione e densità spettrale}%
\label{sub:Correlazione e densità spettrale}
\begin{bluebox}{Correlazione}
    \begin{equation}
        G\left(t\right)=\lim_{T \to \infty} \frac{1}{T}\int_{0}^{T} x\left(t+s\right) x\left(s\right)ds
	\label{eq:Gt_init}
    \end{equation}
\end{bluebox}
\noindent
Se il sistema è ergodico questa definizione è equivalente a quella mediata sull'Ensemble:
\begin{equation}
    G( t) = \left<x(t+s) \cdot  x(s)\right>\label{eq:Gt}
\end{equation}
\begin{bluebox}{Densità spettrale}
    Data la trasformata di Fourier di un segnale $x(t)$:
    \[
	y(\omega) = \int_{0}^{T} x\left(t\right)e^{-i\omega t}dt
    \]
    Si definisce la densità spettrale come:
    \[
        S\left(\omega\right) = \lim_{T \to \infty} \frac{1}{2\pi T}\left|y(\omega) \right|^2
    .\] 
\end{bluebox}
\noindent
Le due definizioni sono legate da una trasformata di Fourier: 
\begin{bluebox}{}
    \begin{align}
	&S\left(\omega\right) = \frac{1}{2\pi}\int G\left(\tau\right)e^{-i\omega \tau}d\tau\\
	&G(t) = \int e^{i\omega t)} S(\omega) d\omega \label{eq:G_inv}
    \end{align}
\end{bluebox}
\noindent
L'equazione \ref{eq:G_inv} risulta particolarmente utile per calcolare la correlazione $G(t)$ di un segnale $x(t)$:
\begin{itemize}
    \item Si calcola la trasformata del segnale $x(\omega)$ (mediante una FFT).
    \item Se ne calcola il modulo quadro $\left| x(\omega) \right|^2$.
    \item Si effettua una trasformata inversa (mediante una RFFT).
\end{itemize}
Se la lunghezza del segnale $x$ è $N$ allora per calcolarne la funzione di correlazione secondo la \ref{eq:Gt_init} è necessario effettuare $N^2$ operazioni, per calcolarla secondo la \ref{eq:G_inv} (quindi tramite la FFT) si effettuano $N\log(N)$ operazioni.
\subsection{Probabilità}%
\label{sub:Probabilità}
Possiamo ripensare una definizione assiomatica della probabilità.
\input{lezioni/tikz/lez_2_prob.tex}
Nella quale $\boldsymbol{x}$ è un evento, $A$ è un set di eventi possibili appartenente ad $\Omega$: l'insieme di tutti gli eventi possibili $(A \in \Omega)$.
\paragraph{Proprietà di $P$ }%
\label{par:Proprietà di P}
\begin{itemize}
    \item $P\left(A\right)\ge 0$.
    \item $P\left(\Omega\right) = 1$.
    \item $P\left(\cup_{i}^{} A_i \right) = \sum_{i}^{} P\left(A_i\right)$ con $A_i$ collezione di insiemi disgiunti numerabile.
    \item $P\left(\overline{A}\right) = 1- P\left(A\right)$.
    \item Se $\omega \in A \cup B$ con $A \cup B = 0$ $\implies$ $\omega\in A \ \lor \ \omega  \in B$.
\end{itemize}
\begin{defn}[Probabilità congiunta]
    Se $A \cap B \neq 0$ allora la probabilità congiunta di un evento $\omega$ è:
    \[
	P(A\cap B) = P(\omega \in A \ e \ \omega \in B)
    \]
\end{defn}
\begin{defn}[Probabilità condizionata]
    La probabilità che avvenga l'evento $A$ sapendo che è già avvenuto un evento $B$ è data da:
    \[
        P\left(A|B\right) = \frac{P\left(A \cap B\right)}{P\left(B\right)}
    .\] 
\end{defn}
Ovviamente si ha anche che:
\[
    P\left(A|B\right)P(B) = P(A)P\left(B|A\right)
.\] 
Prendiamo adesso un insieme $B_i$ di set di eventi:
\[\begin{aligned}
& B_i \cap B_j = \O \quad \forall i,j \\
& \bigcup_{i}^{} B_i = \Omega 
.\end{aligned}\]
Da queste ne deriva che, per il set $A$:
\[
    \begin{WithArrows}
	\bigcup_{i}^{}  \left(A \cap B_i \right) = A \cap \left(\bigcup_{i}^{}  B_i\right) = A \cap \Omega = A &
	\Arrow[jump=2,xoffset=0.5cm]{Utile per} \\
													       &\\
	\sum_{i}^{} P\left(A\cap B_i\right) = P\left(\bigcup_{i}^{} \left(A \cap B_i\right)\right) =  P(A) &
    \end{WithArrows}
.\] 
Per la probabilità congiunta si ha in generale che:
\begin{greenbox}{}
	\[
    		\sum_{i}^{} P\left(A|B_i\right)P(B_i) = \sum_{i}^{} P\left(A \cap B_i\right) = P(A) 
	.\]    
\end{greenbox}
\begin{defn}[Eventi indipendenti]
 Due eventi $x_A, x_B$ si dicono indipendenti se i set a cui appartengono $(A, B)$ rispettano la seguente:
\[
    P(B) P(A|B) = P(A\cap B) = P(A) P(B) 
.\]    
\end{defn}
\noindent
Questa fattorizzazione è valida in generale per eventi indipendenti:
\[
    P\left(\bigcap_i A_i\right) = \prod_i P(A_i) 
.\]    
\paragraph{Valor medio e distribuzione di probabilità}%
\label{par:Valor medio e distribuzione di probabilità}
Sia $R$ una variabile random funzione di un evento $\omega$, il valor medio di $R$ sarà:
 \[
    \left<R\right> = \sum_{\omega}^{} P(\omega) R(\omega) 
.\]    
Possiamo facilmente estendere la definizione al caso continuo, definiamo il set $A(\omega_0, d\omega_0)$ come l'insieme degli eventi $\omega$ tali che:
\[
    \omega  \in \left[\omega_0, \omega_0 + d\omega_0\right]
.\] 
La densità di probabilità di trovare un evento nel set $A(\omega_0, d\omega_0)$ è data da:
\[
    P(\omega_0) d\omega_0 \equiv P\left[A(\omega_0,d\omega_0) \right] \equiv P(\omega_0,d\omega_0) 
.\] 
Quindi il valor medio di $R$ nel continuo:
 \[
    \left<R\right> = \int\limits_{\omega\in \Omega} R(\omega) P(\omega) 
.\]    
\subsection{Funzione caratteristica}%
\label{sub:Funzione caratteristica}
Sia $\vect{x}$ una variabile random con distribuzione di probabilità $P(\vect{x})$, la funzione caratteristica della distribuzione è la sua trasformata di Fourier:
\begin{redbox}{}
    \[
	\phi (\vect{s}) = \int d\vect{x} P(\vect{x}) e^{i \vect{x}\cdot \vect{s}}
    .\] 
\end{redbox}

\begin{exmp}[Distribuzione Gaussiana]
 \[\begin{aligned}
    &P(x) = \frac{e^{-x^2 / 2 \sigma^2}}{\sqrt{2\pi\sigma^2}} 
    &\implies&
    &\phi (s) = e^{-\sigma^2s^2 / 2}
.\end{aligned}\]
\end{exmp}

\begin{exmp}[Distribuzione uniforme]
\[
    P(x) = 
    \begin{cases}
	1 & x \in \left[-\frac{1}{2}, \frac{1}{2}\right]\\
	0 & \text{Altrimenti}
    \end{cases}
\] 
\[
    \phi (s) = \int_{-1 /2}^{1 /2} e^{ixs}dx = \frac{2}{s}\sin\left(\frac{s}{2}\right)  
.\] 
\end{exmp}

\subsubsection{Proprietà della funzione caratteristica}%
\label{ssub:Proprietà della funzione caratteristica}
\begin{enumerate}
    \item $\left|\phi (0) \right|= 1 $.
    \item $\phi (s) $ è continua.
    \item Se $\exists \left<x^n\right>$ allora: 
	\[
		\left<x^n\right> = \left(-i\right)^n \left.\frac{\partial ^n}{\partial s^n} \phi (s)\right|_{s=0} 
	.\] 
    \item Una sequenza di distribuzioni converge ad una distribuzione limite $\iff$ converge la sequenza di funzioni caratteristiche.
    \item Dato $\vect{x} = \left(x_1, \ldots, x_n\right)$ con $x_i$ indipendenti $\forall i$ allora:
	\[ 
	    \phi (s_1, s_2, \ldots) = \prod_{i=1}^{n} \phi (s_i)  
	\]
    \item Se $y = \sum_{i}^{} x_i$ con $x_i$ indipendenti, allora:
	\[
	    \phi (s) = \left<e^{isy}\right> = \prod_{i}^{} \phi_i(s)  
	.\] 
	\begin{exmp}
	    Se $y = x_1 + x_2$ ho che:
	    \[
		P(y) = \int P(x_1) P(y-x_1) dx_1
	    .\] 
	    Allora per le proprietà della trasformata di una convoluzione:
	    \[
		\phi (s) = \phi_1(s) \phi_2(s) 
	    .\] 
	\end{exmp}
\end{enumerate}
\begin{exmp}[Testa o Croce]
    Prendiamo una distribuzione che corrisponda alla probabilità del set di eventi ["testa","croce"] dopo il lancio di una moneta:
    \[
        P(x) = \frac{1}{2}\left( \delta(x-1) + \delta(x+1) \right) 
    \]
    Calcoliamo la funzione caratteristica di tale distribuzione:
    \[
	\phi(s) = \int P(x) e^{isx} dx = \frac{1}{2}\left[ e^{is} + e^{-is} \right] 
    \]
    Ipotizziamo di fare $n$ lanci di moneta e di voler inferire tramite la funzione caratteristica quale sarà la distribuzione di probabilità finale. \\
    Stiamo parlando della probabilità di una somma di eventi indipendenti, quindi per quanto visto in precedenza si ha che:
    \[
	\phi_n(s) = \left[ \phi(s) \right] ^n = \frac{1}{2^n} \left( e^{is} + e^{-is} \right)^n 
    \]
    Si sfrutta la formula binomiale:
    \[
	\phi_n(s) = \frac{1}{2^n}\sum_{k = 0}^{n}\binom{n}{k} e^{is(n-2k)}
    \]
    La trasformata inversa assume la forma di una somma di delta di Dirac che dovrebbero convergere ad una Gaussiana nel limite di $n\to\infty$:
    \[
	P(x) = \frac{1}{2\pi}\int ds \phi_n(s) e^{-ixs} = \frac{1}{2^n} \sum_{k = 0}^{n} \binom{n}{k}\delta(n-2k)
    \]
\end{exmp}
\clearpage
